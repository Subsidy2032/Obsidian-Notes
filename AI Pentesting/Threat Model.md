## Stride

Spoofing
Tampering
Repudiation
Information Disclosure
Denial of Service
Elevation of Privilege

Note: Attacks that query the model are so called perturbation attacks. -> spoofing

### Attack Vectors

Frontend: External API attacks
Model: Exfiltration, backdooring, GANs
Infrastructures and dependencies

## Frontend: External API Attacks

- Bruteforce images to find incorrect predictions
- Smart ML fuzzing to find incorrect predictions
- Performing perturbations to misclassify existing images
- Buffer and Integer overflows in libraries (image processing/rescaling)

### Examples

Test 1: Upload black picture
Test 2: Upload white picture
Test 3: Random pixels until you have pass

Try to compromise the API key(s)

## Model: Exfiltration, Backdooring, GANs

- Attacker gains access to the model - Exfiltration attack and SSH agent hijacking
- Attacker modifies persisted model file - backdooring attack
- Attacker denies modifying the model file - repudiation attack
- Attacker generates realistic fake images using Generative Adversarial Networks (GANs)

### Examples

- Stealing a model file (model file formats like .h5 or keras SaveModel or pkl files)
- Compromised SSH
- Change bias value (bias.assign)
- Backdooring model, changing model file

HDView - UI tools to inspect model files

## Infrastructure and Dependencies

- Attacker poisons the supply chain of third party libraries
- Attacker tampers with images on disk to impact training performance
- Attacker modifies server file to insert a backdoor (key logger, data stealer)
- Pass to cookie attack to gain access to cloud account

### Examples

- $3rd party library is compromised
- Cookie/token theft to gain access to restricted resources
- In-transit modification of data
- Old-fashioned buffer overflows in infrastructure
- DoS attacks - deleting model files, change permissions
